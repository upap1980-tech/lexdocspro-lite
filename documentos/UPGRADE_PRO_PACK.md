# ğŸ“¦ **LEXDOCSPRO LITE v3.0 PRO - UPGRADE PACK**

## ğŸ¯ **QUÃ‰ SE INSTALA:**

### âœ… **Backend Avanzado (run_pro.py)**
- Multi-modelo AI (Ollama, Groq, OpenAI)
- 12 generadores de documentos legales
- Analizador LexNET con cÃ¡lculo de plazos
- OCR integrado (Tesseract)
- Export a iCloud
- Chat contextual
- Dashboard analytics
- BÃºsqueda semÃ¡ntica

### âœ… **Frontend Profesional**
- Interfaz moderna con Tailwind CSS
- 8 secciones principales
- Responsive design
- Dark/Light mode
- Charts y grÃ¡ficos
- Gestor de expedientes

### âœ… **Documentos Generables (12 tipos)**
1. Demanda Civil
2. ContestaciÃ³n a Demanda
3. Recurso de ApelaciÃ³n
4. Demanda Penal
5. Solicitud Medida Cautelar
6. Recurso de Amparo
7. Demanda Laboral
8. Demanda Administrativa
9. Contrato de Servicios
10. Poder Notarial
11. Acta de Junta
12. ClÃ¡usulas Personalizadas

### âœ… **Funciones Avanzadas**
- CÃ¡lculo automÃ¡tico de plazos (Art. 131 LEC)
- AnÃ¡lisis de partes demandantes
- ExtracciÃ³n de jurisdicciÃ³n
- NÃºmero de procedimiento automÃ¡tico
- Medidas cautelares detectadas
- PrÃ³ximos pasos recomendados

---

## ğŸ“¥ **INSTALACIÃ“N PASO A PASO:**

### 1ï¸âƒ£ Descarga los archivos:
```bash
cd ~/Desktop/PROYECTOS/LexDocsPro-LITE
```

### 2ï¸âƒ£ Actualiza requirements.txt
```bash
pip install python-dotenv requests pytesseract pdf2image pillow groq openai
```

### 3ï¸âƒ£ Reemplaza run.py con run_pro.py
```bash
cp run_pro.py run.py
```

### 4ï¸âƒ£ Actualiza HTML/JS
```bash
cp index_pro.html templates/index.html
cp app_pro.js static/js/app.js
```

### 5ï¸âƒ£ Reinicia servidor
```bash
source venv/bin/activate
python run.py
```

### 6ï¸âƒ£ Abre navegador
```
http://localhost:5001
```

---

## ğŸ”Œ **CONFIGURAR MÃšLTIPLES MODELOS:**

### Ollama (Local - YA TIENES)
```bash
ollama serve
# En otra terminal:
ollama pull lexdocs-legal-pro:latest
```

### Groq (Alternativa rÃ¡pida - GRATIS)
1. RegÃ­strate: https://console.groq.com
2. Copia API KEY
3. AÃ±ade a .env:
```
GROQ_API_KEY=tu_key_aqui
```

### OpenAI (Profesional - De pago)
1. RegÃ­strate: https://platform.openai.com
2. Copia API KEY
3. AÃ±ade a .env:
```
OPENAI_API_KEY=tu_key_aqui
```

---

## ğŸ“Š **FUNCIONALIDADES PRINCIPALES:**

### ğŸ¨ **UI/UX**
- Header con branding
- Sidebar de navegaciÃ³n
- 8 secciones
- Selector de modelos
- Status bar en tiempo real

### ğŸ“„ **Generador de Documentos**
- 12 tipos de documentos
- Plantillas inteligentes
- Exportar a TXT/PDF
- EdiciÃ³n en vivo

### ğŸ” **Analizador LexNET**
- Upload de PDFs/TXT
- OCR automÃ¡tico
- ExtracciÃ³n de datos
- CÃ¡lculo de plazos
- Alertas automÃ¡ticas

### ğŸ’¬ **Chat Inteligente**
- Multi-modelo (cambiar en tiempo real)
- Contexto legal espaÃ±ol
- Historial conversacional
- Respuestas formateadas

### ğŸ“š **Gestor de Expedientes**
- CRUD completo
- BÃºsqueda avanzada
- Filtros por tipo/estado
- Export a iCloud

### ğŸ“ˆ **Dashboard**
- EstadÃ­sticas de documentos
- GrÃ¡ficos de actividad
- Modelos mÃ¡s usados
- Ãšltimas consultas

### ğŸ” **Seguridad**
- ValidaciÃ³n de inputs
- CORS configurado
- Error handling robusto
- Logging de operaciones

---

## ğŸ“ **TUTORIAL RÃPIDO:**

### Generar documento:
1. Click en "ğŸ“„ Generador"
2. Selecciona tipo (ej: "Demanda Civil")
3. Escribe descripciÃ³n del caso
4. Click "âš¡ Generar"
5. Click "ğŸ“‹ Copiar" o "ğŸ’¾ Descargar"

### Analizar LexNET:
1. Click en "ğŸ“‹ LexNET"
2. Upload PDF del juzgado
3. Click "ğŸ” Analizar"
4. Recibe:
   - Partes
   - Plazos (con colores de urgencia)
   - PrÃ³ximos pasos

### Chat legal:
1. Click en "ğŸ’¬ Chat"
2. Selecciona modelo (Ollama/Groq/OpenAI)
3. Escribe consulta legal
4. Recibe respuesta contextualizada

---

## ğŸ”§ **TROUBLESHOOTING:**

**P: Â¿Ollama no responde?**
```bash
ollama serve  # En otra terminal
```

**P: Â¿Groq lento?**
- Usa Ollama local (mÃ¡s rÃ¡pido en tu mÃ¡quina)

**P: Â¿PDF no se lee?**
```bash
brew install tesseract  # Instala OCR
```

**P: Â¿CORS error?**
- Backend ya tiene CORS configurado

**P: Â¿Puerto 5001 en uso?**
```bash
lsof -i :5001  # Ver quÃ© lo usa
kill -9 <PID>  # Matar proceso
```

---

## ğŸ“ **SOPORTE:**

Si algo falla:
1. Verifica que Ollama estÃ© corriendo
2. Check `http://localhost:5001/api/chat` devuelve error
3. Revisa terminal del servidor por errores
4. Limpia cache del navegador (Cmd+Shift+R)

---

**Â¡LISTO PARA INSTALAR!** ğŸš€

Copia los 3 archivos (run_pro.py, index_pro.html, app_pro.js) en el proyecto y ejecuta el setup.
